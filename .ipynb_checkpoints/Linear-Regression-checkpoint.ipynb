{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = var(torch.Tensor([[1.0],[2.0],[3.0]]))\n",
    "y_data = var(torch.Tensor([[2.0],[4.0],[6.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model,self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)  # One in and one out\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-installation\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(size_average=False)  # size_average\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17.583284378051758\n",
      "1 8.09745979309082\n",
      "2 3.870758295059204\n",
      "3 1.9853291511535645\n",
      "4 1.1422221660614014\n",
      "5 0.7631805539131165\n",
      "6 0.590782105922699\n",
      "7 0.5104270577430725\n",
      "8 0.4710996150970459\n",
      "9 0.45008742809295654\n",
      "10 0.43727847933769226\n",
      "11 0.42817196249961853\n",
      "12 0.42076167464256287\n",
      "13 0.4141558110713959\n",
      "14 0.40795445442199707\n",
      "15 0.40198057889938354\n",
      "16 0.3961542546749115\n",
      "17 0.39043864607810974\n",
      "18 0.3848176896572113\n",
      "19 0.37928307056427\n",
      "20 0.37383025884628296\n",
      "21 0.36845672130584717\n",
      "22 0.3631610572338104\n",
      "23 0.3579418957233429\n",
      "24 0.3527972996234894\n",
      "25 0.34772709012031555\n",
      "26 0.34272995591163635\n",
      "27 0.33780425786972046\n",
      "28 0.33294931054115295\n",
      "29 0.32816430926322937\n",
      "30 0.32344818115234375\n",
      "31 0.31879985332489014\n",
      "32 0.31421831250190735\n",
      "33 0.30970218777656555\n",
      "34 0.30525144934654236\n",
      "35 0.30086445808410645\n",
      "36 0.2965404689311981\n",
      "37 0.29227879643440247\n",
      "38 0.2880781888961792\n",
      "39 0.28393813967704773\n",
      "40 0.27985748648643494\n",
      "41 0.2758353054523468\n",
      "42 0.27187126874923706\n",
      "43 0.2679641842842102\n",
      "44 0.2641129493713379\n",
      "45 0.26031702756881714\n",
      "46 0.2565762996673584\n",
      "47 0.25288882851600647\n",
      "48 0.24925437569618225\n",
      "49 0.24567198753356934\n",
      "50 0.2421414852142334\n",
      "51 0.2386614978313446\n",
      "52 0.23523138463497162\n",
      "53 0.2318510115146637\n",
      "54 0.2285187989473343\n",
      "55 0.22523479163646698\n",
      "56 0.22199776768684387\n",
      "57 0.21880705654621124\n",
      "58 0.2156623750925064\n",
      "59 0.21256326138973236\n",
      "60 0.20950834453105927\n",
      "61 0.20649729669094086\n",
      "62 0.20352953672409058\n",
      "63 0.20060472190380096\n",
      "64 0.1977214217185974\n",
      "65 0.19487997889518738\n",
      "66 0.1920793503522873\n",
      "67 0.18931879103183746\n",
      "68 0.1865978091955185\n",
      "69 0.18391616642475128\n",
      "70 0.18127307295799255\n",
      "71 0.17866797745227814\n",
      "72 0.17610038816928864\n",
      "73 0.17356924712657928\n",
      "74 0.17107480764389038\n",
      "75 0.16861626505851746\n",
      "76 0.16619300842285156\n",
      "77 0.1638045758008957\n",
      "78 0.16145049035549164\n",
      "79 0.1591300517320633\n",
      "80 0.15684334933757782\n",
      "81 0.15458907186985016\n",
      "82 0.1523675173521042\n",
      "83 0.15017759799957275\n",
      "84 0.1480191946029663\n",
      "85 0.1458919793367386\n",
      "86 0.14379538595676422\n",
      "87 0.1417289674282074\n",
      "88 0.13969199359416962\n",
      "89 0.1376844048500061\n",
      "90 0.13570544123649597\n",
      "91 0.13375510275363922\n",
      "92 0.13183297216892242\n",
      "93 0.12993817031383514\n",
      "94 0.12807093560695648\n",
      "95 0.12623032927513123\n",
      "96 0.12441618740558624\n",
      "97 0.12262817472219467\n",
      "98 0.12086579203605652\n",
      "99 0.11912868916988373\n",
      "100 0.11741674691438675\n",
      "101 0.11572908610105515\n",
      "102 0.11406591534614563\n",
      "103 0.11242667585611343\n",
      "104 0.1108110323548317\n",
      "105 0.10921838134527206\n",
      "106 0.10764872282743454\n",
      "107 0.10610169172286987\n",
      "108 0.10457687824964523\n",
      "109 0.10307390242815018\n",
      "110 0.10159268975257874\n",
      "111 0.10013242810964584\n",
      "112 0.09869333356618881\n",
      "113 0.0972750261425972\n",
      "114 0.0958772674202919\n",
      "115 0.09449931979179382\n",
      "116 0.09314116835594177\n",
      "117 0.09180256724357605\n",
      "118 0.09048313647508621\n",
      "119 0.08918265253305435\n",
      "120 0.08790118247270584\n",
      "121 0.08663788437843323\n",
      "122 0.0853927880525589\n",
      "123 0.08416549116373062\n",
      "124 0.08295571804046631\n",
      "125 0.08176366239786148\n",
      "126 0.08058870583772659\n",
      "127 0.07943026721477509\n",
      "128 0.07828894257545471\n",
      "129 0.07716360688209534\n",
      "130 0.0760548785328865\n",
      "131 0.07496175169944763\n",
      "132 0.07388439774513245\n",
      "133 0.07282258570194244\n",
      "134 0.07177603989839554\n",
      "135 0.07074441760778427\n",
      "136 0.06972764432430267\n",
      "137 0.06872566044330597\n",
      "138 0.06773799657821655\n",
      "139 0.06676448881626129\n",
      "140 0.06580491364002228\n",
      "141 0.06485925614833832\n",
      "142 0.06392701715230942\n",
      "143 0.06300822645425797\n",
      "144 0.06210274621844292\n",
      "145 0.06121044233441353\n",
      "146 0.06033060699701309\n",
      "147 0.059463661164045334\n",
      "148 0.05860906094312668\n",
      "149 0.05776669457554817\n",
      "150 0.05693645775318146\n",
      "151 0.0561181977391243\n",
      "152 0.0553116574883461\n",
      "153 0.054516781121492386\n",
      "154 0.053733278065919876\n",
      "155 0.05296102538704872\n",
      "156 0.05219985917210579\n",
      "157 0.05144977197051048\n",
      "158 0.05071035027503967\n",
      "159 0.049981504678726196\n",
      "160 0.0492631234228611\n",
      "161 0.04855523258447647\n",
      "162 0.047857411205768585\n",
      "163 0.047169607132673264\n",
      "164 0.04649170860648155\n",
      "165 0.04582349583506584\n",
      "166 0.045164961367845535\n",
      "167 0.04451584443449974\n",
      "168 0.04387606680393219\n",
      "169 0.04324546456336975\n",
      "170 0.04262414574623108\n",
      "171 0.04201146960258484\n",
      "172 0.04140770062804222\n",
      "173 0.04081260412931442\n",
      "174 0.04022609069943428\n",
      "175 0.03964795544743538\n",
      "176 0.03907814621925354\n",
      "177 0.03851654380559921\n",
      "178 0.03796293959021568\n",
      "179 0.037417422980070114\n",
      "180 0.036879707127809525\n",
      "181 0.03634968772530556\n",
      "182 0.03582717850804329\n",
      "183 0.03531230613589287\n",
      "184 0.03480484336614609\n",
      "185 0.03430464491248131\n",
      "186 0.03381158784031868\n",
      "187 0.033325739204883575\n",
      "188 0.03284670412540436\n",
      "189 0.03237475827336311\n",
      "190 0.03190946951508522\n",
      "191 0.031450897455215454\n",
      "192 0.030998889356851578\n",
      "193 0.030553366988897324\n",
      "194 0.03011423535645008\n",
      "195 0.029681488871574402\n",
      "196 0.029254937544465065\n",
      "197 0.0288343857973814\n",
      "198 0.02842007391154766\n",
      "199 0.02801165170967579\n",
      "200 0.027608994394540787\n",
      "201 0.02721233293414116\n",
      "202 0.026821112260222435\n",
      "203 0.026435712352395058\n",
      "204 0.026055729016661644\n",
      "205 0.025681374594569206\n",
      "206 0.025312284007668495\n",
      "207 0.02494846284389496\n",
      "208 0.02458985522389412\n",
      "209 0.024236442521214485\n",
      "210 0.023888176307082176\n",
      "211 0.023544928058981895\n",
      "212 0.023206528276205063\n",
      "213 0.022873014211654663\n",
      "214 0.02254433184862137\n",
      "215 0.022220196202397346\n",
      "216 0.021900884807109833\n",
      "217 0.021586181595921516\n",
      "218 0.021275971084833145\n",
      "219 0.020970212295651436\n",
      "220 0.020668787881731987\n",
      "221 0.02037176303565502\n",
      "222 0.020078938454389572\n",
      "223 0.01979048177599907\n",
      "224 0.01950599066913128\n",
      "225 0.019225677475333214\n",
      "226 0.018949370831251144\n",
      "227 0.01867702789604664\n",
      "228 0.01840864308178425\n",
      "229 0.01814408041536808\n",
      "230 0.017883336171507835\n",
      "231 0.017626294866204262\n",
      "232 0.017372984439134598\n",
      "233 0.017123280093073845\n",
      "234 0.01687724143266678\n",
      "235 0.016634661704301834\n",
      "236 0.016395626589655876\n",
      "237 0.01615997590124607\n",
      "238 0.015927786007523537\n",
      "239 0.015698790550231934\n",
      "240 0.01547324750572443\n",
      "241 0.015250829048454762\n",
      "242 0.015031682327389717\n",
      "243 0.01481560803949833\n",
      "244 0.014602706767618656\n",
      "245 0.014392866753041744\n",
      "246 0.01418600045144558\n",
      "247 0.013982163742184639\n",
      "248 0.013781175017356873\n",
      "249 0.013583125546574593\n",
      "250 0.013387908227741718\n",
      "251 0.013195493258535862\n",
      "252 0.013005870394408703\n",
      "253 0.012818949297070503\n",
      "254 0.012634688057005405\n",
      "255 0.01245308481156826\n",
      "256 0.012274123728275299\n",
      "257 0.01209776196628809\n",
      "258 0.011923921294510365\n",
      "259 0.011752542108297348\n",
      "260 0.01158363651484251\n",
      "261 0.011417183093726635\n",
      "262 0.011253075674176216\n",
      "263 0.011091307736933231\n",
      "264 0.010931969620287418\n",
      "265 0.010774852707982063\n",
      "266 0.010619986802339554\n",
      "267 0.010467366315424442\n",
      "268 0.010316937230527401\n",
      "269 0.010168652981519699\n",
      "270 0.010022541508078575\n",
      "271 0.009878470562398434\n",
      "272 0.00973652582615614\n",
      "273 0.009596572257578373\n",
      "274 0.009458660148084164\n",
      "275 0.00932273454964161\n",
      "276 0.009188729338347912\n",
      "277 0.00905667245388031\n",
      "278 0.008926511742174625\n",
      "279 0.008798236958682537\n",
      "280 0.008671783842146397\n",
      "281 0.008547180332243443\n",
      "282 0.008424333296716213\n",
      "283 0.008303223177790642\n",
      "284 0.008183920755982399\n",
      "285 0.008066306822001934\n",
      "286 0.007950368337333202\n",
      "287 0.007836109027266502\n",
      "288 0.007723503280431032\n",
      "289 0.007612524554133415\n",
      "290 0.007503094617277384\n",
      "291 0.007395281456410885\n",
      "292 0.007289028260856867\n",
      "293 0.007184273097664118\n",
      "294 0.007080971263349056\n",
      "295 0.006979223806411028\n",
      "296 0.006878902204334736\n",
      "297 0.006780048832297325\n",
      "298 0.00668264739215374\n",
      "299 0.006586569361388683\n",
      "300 0.00649191252887249\n",
      "301 0.006398639176040888\n",
      "302 0.006306654307991266\n",
      "303 0.006216027773916721\n",
      "304 0.00612673070281744\n",
      "305 0.006038667634129524\n",
      "306 0.0059518963098526\n",
      "307 0.005866331979632378\n",
      "308 0.005782045889645815\n",
      "309 0.005698918830603361\n",
      "310 0.0056170206516981125\n",
      "311 0.005536290816962719\n",
      "312 0.005456746555864811\n",
      "313 0.005378306843340397\n",
      "314 0.005300997756421566\n",
      "315 0.005224841181188822\n",
      "316 0.005149727687239647\n",
      "317 0.005075725726783276\n",
      "318 0.0050027817487716675\n",
      "319 0.00493088411167264\n",
      "320 0.004860025830566883\n",
      "321 0.00479018734768033\n",
      "322 0.004721330013126135\n",
      "323 0.004653498064726591\n",
      "324 0.004586606286466122\n",
      "325 0.004520691465586424\n",
      "326 0.004455722868442535\n",
      "327 0.0043917144648730755\n",
      "328 0.004328570328652859\n",
      "329 0.004266365896910429\n",
      "330 0.004205022938549519\n",
      "331 0.0041446140967309475\n",
      "332 0.004085029009729624\n",
      "333 0.0040263403207063675\n",
      "334 0.003968486562371254\n",
      "335 0.0039114258252084255\n",
      "336 0.0038552475161850452\n",
      "337 0.0037997912149876356\n",
      "338 0.0037452345713973045\n",
      "339 0.0036913729272782803\n",
      "340 0.0036383222322911024\n",
      "341 0.00358604546636343\n",
      "342 0.0035345065407454967\n",
      "343 0.0034836940467357635\n",
      "344 0.0034336585085839033\n",
      "345 0.0033842958509922028\n",
      "346 0.0033356635831296444\n",
      "347 0.0032877065241336823\n",
      "348 0.003240464022383094\n",
      "349 0.003193911863490939\n",
      "350 0.0031479899771511555\n",
      "351 0.0031027570366859436\n",
      "352 0.003058169735595584\n",
      "353 0.003014208283275366\n",
      "354 0.002970878966152668\n",
      "355 0.0029281903989613056\n",
      "356 0.0028861169703304768\n",
      "357 0.0028446302749216557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 0.0028037517331540585\n",
      "359 0.002763480879366398\n",
      "360 0.0027237622998654842\n",
      "361 0.0026846113614737988\n",
      "362 0.002646025037392974\n",
      "363 0.002607970265671611\n",
      "364 0.002570515498518944\n",
      "365 0.0025335687678307295\n",
      "366 0.002497159643098712\n",
      "367 0.0024612650740891695\n",
      "368 0.0024258936755359173\n",
      "369 0.002391011454164982\n",
      "370 0.0023566726595163345\n",
      "371 0.002322789514437318\n",
      "372 0.0022894300054758787\n",
      "373 0.0022565105464309454\n",
      "374 0.0022240765392780304\n",
      "375 0.002192108426243067\n",
      "376 0.0021606285590678453\n",
      "377 0.002129575004801154\n",
      "378 0.00209896732121706\n",
      "379 0.0020688059739768505\n",
      "380 0.002039083279669285\n",
      "381 0.00200976082123816\n",
      "382 0.0019809019286185503\n",
      "383 0.0019524237141013145\n",
      "384 0.0019243455026298761\n",
      "385 0.0018967112991958857\n",
      "386 0.0018694628961384296\n",
      "387 0.0018425689777359366\n",
      "388 0.0018160805338993669\n",
      "389 0.0017899929080158472\n",
      "390 0.001764260116033256\n",
      "391 0.0017389125423505902\n",
      "392 0.0017139263218268752\n",
      "393 0.0016892787534743547\n",
      "394 0.001665025600232184\n",
      "395 0.0016410938696935773\n",
      "396 0.0016175013734027743\n",
      "397 0.0015942584723234177\n",
      "398 0.0015713588800281286\n",
      "399 0.0015487737255170941\n",
      "400 0.001526499749161303\n",
      "401 0.0015045630279928446\n",
      "402 0.0014829350402578712\n",
      "403 0.0014616281259804964\n",
      "404 0.0014406233094632626\n",
      "405 0.0014199195429682732\n",
      "406 0.0013995090266689658\n",
      "407 0.0013793975813314319\n",
      "408 0.0013595710042864084\n",
      "409 0.0013400326715782285\n",
      "410 0.0013207794399932027\n",
      "411 0.001301803975366056\n",
      "412 0.0012830907944589853\n",
      "413 0.0012646372197195888\n",
      "414 0.0012464690953493118\n",
      "415 0.0012285689590498805\n",
      "416 0.001210891525261104\n",
      "417 0.0011935026850551367\n",
      "418 0.0011763354996219277\n",
      "419 0.0011594390962272882\n",
      "420 0.0011427788995206356\n",
      "421 0.0011263447813689709\n",
      "422 0.0011101748095825315\n",
      "423 0.001094202627427876\n",
      "424 0.0010784817859530449\n",
      "425 0.0010629845783114433\n",
      "426 0.0010477086761966348\n",
      "427 0.0010326573392376304\n",
      "428 0.0010178039083257318\n",
      "429 0.0010031888959929347\n",
      "430 0.0009887617779895663\n",
      "431 0.0009745499701239169\n",
      "432 0.0009605509112589061\n",
      "433 0.0009467300260439515\n",
      "434 0.0009331265464425087\n",
      "435 0.0009197326144203544\n",
      "436 0.0009065072517842054\n",
      "437 0.00089347327593714\n",
      "438 0.0008806268451735377\n",
      "439 0.0008679950842633843\n",
      "440 0.0008555107051506639\n",
      "441 0.0008432112517766654\n",
      "442 0.000831094803288579\n",
      "443 0.0008191491942852736\n",
      "444 0.0008073793142102659\n",
      "445 0.0007957650814205408\n",
      "446 0.0007843343773856759\n",
      "447 0.0007730574579909444\n",
      "448 0.000761947245337069\n",
      "449 0.0007510019931942225\n",
      "450 0.0007402070332318544\n",
      "451 0.0007295797113329172\n",
      "452 0.0007190932519733906\n",
      "453 0.000708750740159303\n",
      "454 0.0006985723157413304\n",
      "455 0.0006885345792397857\n",
      "456 0.0006786316516809165\n",
      "457 0.000668875640258193\n",
      "458 0.0006592678837478161\n",
      "459 0.0006497874273918569\n",
      "460 0.0006404609302990139\n",
      "461 0.0006312457844614983\n",
      "462 0.0006221843650564551\n",
      "463 0.0006132330745458603\n",
      "464 0.0006044224719516933\n",
      "465 0.0005957266548648477\n",
      "466 0.0005871769972145557\n",
      "467 0.0005787436966784298\n",
      "468 0.000570421339944005\n",
      "469 0.0005622213357128203\n",
      "470 0.000554131343960762\n",
      "471 0.0005461720284074545\n",
      "472 0.0005383201641961932\n",
      "473 0.0005305974627844989\n",
      "474 0.0005229584639891982\n",
      "475 0.000515444902703166\n",
      "476 0.0005080432747490704\n",
      "477 0.0005007433355785906\n",
      "478 0.0004935440956614912\n",
      "479 0.000486454606289044\n",
      "480 0.0004794559208676219\n",
      "481 0.00047257618280127645\n",
      "482 0.00046578131150454283\n",
      "483 0.0004590879543684423\n",
      "484 0.00045247768866829574\n",
      "485 0.00044598535168915987\n",
      "486 0.0004395655123516917\n",
      "487 0.00043325754813849926\n",
      "488 0.00042703005601651967\n",
      "489 0.0004208941536489874\n",
      "490 0.0004148452717345208\n",
      "491 0.00040888250805437565\n",
      "492 0.000402999110519886\n",
      "493 0.0003972220583818853\n",
      "494 0.0003915017005056143\n",
      "495 0.00038588218740187585\n",
      "496 0.0003803294093813747\n",
      "497 0.0003748641174752265\n",
      "498 0.0003694753104355186\n",
      "499 0.00036417320370674133\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (after training) 4 tensor(7.9781)\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "hour_var = var(torch.Tensor([[4.0]]))\n",
    "y_pred = model(hour_var)\n",
    "print(\"predict (after training)\",  4, model(hour_var).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
