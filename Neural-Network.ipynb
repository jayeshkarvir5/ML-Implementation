{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./data/diabetes.csv.gz',\n",
    "                        delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.as_tensor(xy[:, 0:-1])\n",
    "        self.y_data = torch.as_tensor(xy[:, [-1]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                         )\n",
    "#                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.x_data.shape\n",
    "# dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "#         self.l = torch.nn.Linear(8, 1)\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))  # self.sigmoid(self.l3(out2))\n",
    "#         y_pred = torch.sigmoid(self.l(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-installation\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.6813559532165527\n",
      "0 1 0.6620967984199524\n",
      "0 2 0.6067146062850952\n",
      "0 3 0.605440080165863\n",
      "0 4 0.7794202566146851\n",
      "0 5 0.68024742603302\n",
      "0 6 0.5551309585571289\n",
      "0 7 0.5302925109863281\n",
      "0 8 0.522497832775116\n",
      "0 9 0.6434274315834045\n",
      "0 10 0.6007947325706482\n",
      "0 11 0.665336549282074\n",
      "0 12 0.792884349822998\n",
      "0 13 0.6034555435180664\n",
      "0 14 0.6431500315666199\n",
      "0 15 0.5822877287864685\n",
      "0 16 0.7059715986251831\n",
      "0 17 0.5619320869445801\n",
      "0 18 0.7277249097824097\n",
      "0 19 0.7646729946136475\n",
      "0 20 0.643311619758606\n",
      "0 21 0.6817480325698853\n",
      "0 22 0.6811923384666443\n",
      "0 23 0.5688859224319458\n",
      "1 0 0.7206230163574219\n",
      "1 1 0.6064573526382446\n",
      "1 2 0.6624547839164734\n",
      "1 3 0.7004799246788025\n",
      "1 4 0.569858193397522\n",
      "1 5 0.6048627495765686\n",
      "1 6 0.5841031670570374\n",
      "1 7 0.5820891261100769\n",
      "1 8 0.6434257626533508\n",
      "1 9 0.7059959173202515\n",
      "1 10 0.7443854212760925\n",
      "1 11 0.5856154561042786\n",
      "1 12 0.6631914973258972\n",
      "1 13 0.6235870122909546\n",
      "1 14 0.6829575300216675\n",
      "1 15 0.6043660044670105\n",
      "1 16 0.6430823802947998\n",
      "1 17 0.7034450769424438\n",
      "1 18 0.6237371563911438\n",
      "1 19 0.6235508322715759\n",
      "1 20 0.663354754447937\n",
      "1 21 0.6235551238059998\n",
      "1 22 0.6434261202812195\n",
      "1 23 0.7016515135765076\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(100):\n",
    "#     # Forward pass: Compute predicted y by passing x to the model\n",
    "#     y_pred = model(dataset.x_data)\n",
    "\n",
    "#     # Compute and print loss\n",
    "#     loss = criterion(y_pred, dataset.y_data)\n",
    "#     print(epoch, loss.item())\n",
    "\n",
    "#     # Zero gradients, perform a backward pass, and update the weights.\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        print(epoch, i, loss.item())\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# def train(epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = Variable(data), Variable(target)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
